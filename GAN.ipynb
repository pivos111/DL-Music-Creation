{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWReWjdRjQ6P"
      },
      "source": [
        "# Using GANs to Generate Music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfcYQM4qjTis"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import pretty_midi\n",
        "import pypianoroll\n",
        "import tables\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "import music21\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "import json\n",
        "import IPython.display\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "import random\n",
        "import itertools\n",
        "root_dir = 'drive/MyDrive/ProjectMusic'\n",
        "data_dir = root_dir + '/Lakh Piano Dataset/LPD-5/lpd_5/lpd_5_cleansed'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMex7xeZoaor",
        "outputId": "784c9032-28cc-4338-fcd1-9bf4d87f673b"
      },
      "outputs": [],
      "source": [
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "!pip install music21\n",
        "!pip install pypianoroll"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhR5l1SjNTa5"
      },
      "source": [
        "**Getting MIDI and Song Metadata**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng13lLDrN8Za"
      },
      "outputs": [],
      "source": [
        "RESULTS_PATH = os.path.join(root_dir, 'Lakh Piano Dataset', 'Metadata')\n",
        "\n",
        "# Utility functions for retrieving paths\n",
        "def msd_id_to_dirs(msd_id):\n",
        "    \"\"\"Given an MSD ID, generate the path prefix.\n",
        "    E.g. TRABCD12345678 -> A/B/C/TRABCD12345678\"\"\"\n",
        "    return os.path.join(msd_id[2], msd_id[3], msd_id[4], msd_id)\n",
        "\n",
        "\n",
        "def msd_id_to_h5(msd_id):\n",
        "    \"\"\"Given an MSD ID, return the path to the corresponding h5\"\"\"\n",
        "    return os.path.join(RESULTS_PATH, 'lmd_matched_h5',\n",
        "                        msd_id_to_dirs(msd_id) + '.h5')\n",
        "\n",
        "# Load the midi npz file from the LMD cleansed folder\n",
        "def get_midi_npz_path(msd_id, midi_md5):\n",
        "    return os.path.join(data_dir,\n",
        "                        msd_id_to_dirs(msd_id), midi_md5 + '.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY-AyplDYXSm",
        "outputId": "0f2bf329-a6ee-4ed3-e9e2-b6bda9e38f75"
      },
      "outputs": [],
      "source": [
        "# Open the cleansed ids - cleansed file ids : msd ids\n",
        "cleansed_ids = pd.read_csv(os.path.join(root_dir, 'Lakh Piano Dataset', 'cleansed_ids.txt'), delimiter = '    ', header = None)\n",
        "lpd_to_msd_ids = {a:b for a, b in zip(cleansed_ids[0], cleansed_ids[1])}\n",
        "msd_to_lpd_ids = {a:b for a, b in zip(cleansed_ids[1], cleansed_ids[0])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGhaBVSOzweZ"
      },
      "outputs": [],
      "source": [
        "# Reading the genre annotations\n",
        "genre_file_dir = os.path.join(root_dir, 'Lakh Piano Dataset', 'Genre', 'msd_tagtraum_cd1.cls')\n",
        "ids = []\n",
        "genres = []\n",
        "with open(genre_file_dir) as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "        if line[0] != '#':\n",
        "          split = line.strip().split(\"\\t\")\n",
        "          if len(split) == 2:\n",
        "            ids.append(split[0])\n",
        "            genres.append(split[1])\n",
        "          elif len(split) == 3:\n",
        "            ids.append(split[0])\n",
        "            ids.append(split[0])\n",
        "            genres.append(split[1])\n",
        "            genres.append(split[2])\n",
        "        line = f.readline()\n",
        "genre_df = pd.DataFrame(data={\"TrackID\": ids, \"Genre\": genres})\n",
        "\n",
        "genre_dict = genre_df.groupby('TrackID')['Genre'].apply(lambda x: x.tolist()).to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Le14xf4NVd"
      },
      "source": [
        "**Objects that we need**\n",
        "\n",
        "- cleansed_ids: dictionary of LPD file name : MSD file name\n",
        "- lmd_metadata: list of dictionaries - each dict has a msd_id field to identify\n",
        "- Get the lmd_file_name (actual path )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOeVzvnwV2ht"
      },
      "outputs": [],
      "source": [
        "# Load the processed metadata\n",
        "with open(os.path.join(root_dir, 'Lakh Piano Dataset', 'processed_metadata.json'), 'r') as outfile:\n",
        "  lmd_metadata = json.load(outfile)\n",
        "\n",
        "# Change this into a dictionary of MSD_ID: metadata\n",
        "lmd_metadata = {e['msd_id']:e for e in lmd_metadata}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU0th4Rt5ZMu"
      },
      "outputs": [],
      "source": [
        "# Get all song MSD IDs in pop rock genre\n",
        "rock_song_msd_ids = [k for k, v in lmd_metadata.items() if 'rock' in v['artist_terms']]\n",
        "\n",
        "# Randomly choose 1000 songs out of these\n",
        "train_ids = random.choices(rock_song_msd_ids, k = 5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xM2flv96PUg"
      },
      "outputs": [],
      "source": [
        "combined_pianorolls = []\n",
        "i = 0\n",
        "for msd_file_name in train_ids:\n",
        "\n",
        "  lpd_file_name = msd_to_lpd_ids[msd_file_name]\n",
        "  # Get the NPZ path\n",
        "  npz_path = get_midi_npz_path(msd_file_name, lpd_file_name)\n",
        "  multitrack = pypianoroll.load(npz_path)\n",
        "  multitrack.set_resolution(4).pad_to_same()\n",
        "\n",
        "  # Piano, Guitar, Bass, Strings, Drums\n",
        "  # Splitting into different parts\n",
        "\n",
        "  parts = {'piano_part': None, 'guitar_part': None, 'bass_part': None, 'strings_part': None, 'drums_part': None}\n",
        "  song_length = None\n",
        "  empty_array = None\n",
        "  has_empty_parts = False\n",
        "  for track in multitrack.tracks:\n",
        "    if track.name == 'Drums':\n",
        "      parts['drums_part'] = track.pianoroll\n",
        "    if track.name == 'Piano':\n",
        "      parts['piano_part'] = track.pianoroll\n",
        "    if track.name == 'Guitar':\n",
        "      parts['guitar_part'] = track.pianoroll\n",
        "    if track.name == 'Bass':\n",
        "      parts['bass_part'] = track.pianoroll\n",
        "    if track.name == 'Strings':\n",
        "      parts['strings_part'] = track.pianoroll\n",
        "    if track.pianoroll.shape[0] > 0:\n",
        "      empty_array = np.zeros_like(track.pianoroll)\n",
        "\n",
        "  for k,v in parts.items():\n",
        "    if v.shape[0] == 0:\n",
        "      parts[k] = empty_array.copy()\n",
        "      has_empty_parts = True\n",
        "\n",
        "  # Stack all together - Piano, Guitar, Bass, Strings, Drums\n",
        "  combined_pianoroll = torch.tensor([parts['piano_part'], parts['guitar_part'], parts['bass_part'], parts['strings_part'], parts['drums_part']])\n",
        "\n",
        "  # These contain velocity information - the force with which the notes are hit - which can be standardized to 0/1 if we want (to compress)\n",
        "  if has_empty_parts == False:\n",
        "    combined_pianorolls.append(combined_pianoroll)\n",
        "    i+=1\n",
        "    print(i)\n",
        "\n",
        "  if i == 200:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seLMQnkXDIad"
      },
      "outputs": [],
      "source": [
        "# Loading\n",
        "combined_pianorolls = torch.load(os.path.join(root_dir, 'Lakh Piano Dataset', 'rock_1000_pianorolls.pt'))\n",
        "pianoroll_lengths = torch.load(os.path.join(root_dir, 'Lakh Piano Dataset', 'rock_1000_pianorolls_lengths.pt'))\n",
        "pianoroll_lengths = pianoroll_lengths.numpy()\n",
        "pianoroll_cum_lengths = pianoroll_lengths.cumsum()\n",
        "\n",
        "# Remake the list of pianorolls\n",
        "pianorolls_list = []\n",
        "pianorolls_list.append(combined_pianorolls[:, :pianoroll_cum_lengths[0], :])\n",
        "for i in range(len(pianoroll_cum_lengths) - 1):\n",
        "  pianorolls_list.append(combined_pianorolls[:, pianoroll_cum_lengths[i]:pianoroll_cum_lengths[i+1], :])\n",
        "\n",
        "#combined_pianorolls = pianorolls_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3lZ7cHoGMcW"
      },
      "outputs": [],
      "source": [
        "# Creating dataset and dataloader\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REA0KkIlQxeo"
      },
      "outputs": [],
      "source": [
        "mini_data = pianorolls_list[100:200]\n",
        "mini_data_concat = torch.hstack(mini_data)\n",
        "mini_data_concat = mini_data_concat[:, :, 24:96]\n",
        "mini_data_concat_binary = mini_data_concat.clone()\n",
        "mini_data_concat_binary[mini_data_concat_binary > 0.2] = 1.0\n",
        "mini_data_concat_binary = mini_data_concat_binary.type(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9GJDaChQLHx"
      },
      "outputs": [],
      "source": [
        "# Deterministic dataset that does not change over epochs\n",
        "class GANMusicDatasetDeterministic(Dataset):\n",
        "  def __init__(self, data, seq_length = 64):\n",
        "\n",
        "    # Normalize\n",
        "    #data = data / 127\n",
        "\n",
        "    self.data = data\n",
        "    self.seq_length = seq_length\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x = self.data[:, (index * self.seq_length):(index+1) * self.seq_length, :]\n",
        "    return x\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(self.data.size(1) / self.seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlJWAAUG4cLi"
      },
      "outputs": [],
      "source": [
        "# Get the 10000 random sequences\n",
        "class GANMusicDataset(Dataset):\n",
        "  def __init__(self, list_of_sequences, dataset_length = 32 * 10000, seq_length = 64):\n",
        "\n",
        "    # Normalize\n",
        "    list_of_sequences = [e / 127.0 for e in list_of_sequences]\n",
        "\n",
        "    self.data = list_of_sequences\n",
        "    self.n_songs = len(list_of_sequences)\n",
        "    self.seq_length = seq_length\n",
        "    self.length = dataset_length\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    # Choose a random song id\n",
        "    song_id = random.randint(0, self.n_songs - 1)\n",
        "    song_length = self.data[song_id].size()[1]\n",
        "\n",
        "    # Choose a random start window - the prev_x_sequence and x_sequence are consecutive, non-overlapping chunks of length 64\n",
        "    start_time = random.randint(0, song_length - self.seq_length * 2 - 1)\n",
        "    #prev_x_sequence = self.data[song_id][:, start_time:(start_time + self.seq_length), :]\n",
        "    x_sequence = self.data[song_id][:, (start_time + self.seq_length):(start_time + self.seq_length * 2), :]\n",
        "\n",
        "    # Give a random chord (0 for now)\n",
        "    #chord = torch.zeros(13, dtype = torch.float32)\n",
        "\n",
        "    #print(start_time, start_time + self.seq_length, start_time + self.seq_length * 2)\n",
        "\n",
        "    return x_sequence\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMAVN7vJ6EK2"
      },
      "outputs": [],
      "source": [
        "# TESTING CODE\n",
        "dataset = GANMusicDataset(pianorolls_list, seq_length = 16)\n",
        "loader = DataLoader(dataset, batch_size = 64, \n",
        "                                     drop_last=True)\n",
        "\n",
        "x_sequence = next(iter(loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDI-AniPUJwc"
      },
      "source": [
        "**GAN Generation Code (from Lecture)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt7gdpCFc3KC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import random\n",
        "import pathlib\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision.utils import make_grid\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def progress(batch, loss, batches):\n",
        "    return HTML(\"\"\"\n",
        "        <label for=\"file\">Training loss: {loss}</label>\n",
        "        <progress\n",
        "            value='{batch}'\n",
        "            max='{batches}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {batch}\n",
        "        </progress>\n",
        "    \"\"\".format(loss=loss, batch=batch, batches=batches))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo2jIUyXWFOi"
      },
      "outputs": [],
      "source": [
        "def sigmoid_cross_entropy_with_logits(inputs,labels):\n",
        "    loss = nn.BCEWithLogitsLoss()\n",
        "    output = loss(inputs, labels)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wOXoyqfUMRm"
      },
      "outputs": [],
      "source": [
        "def train_full_GAN(gen, disc,\n",
        "                    loader, z_dim, \n",
        "                    epochs=5, disp_batch_size = 24, start_epoch = 0):\n",
        "    gen.to(device).train()\n",
        "    disc.to(device).train()\n",
        "\n",
        "    disc_opt = torch.optim.Adam(disc.parameters(), lr= 0.0006, betas=(0.0, 0.99))\n",
        "    gen_opt = torch.optim.Adam(gen.parameters(), lr = 0.0003, betas=(0.0, 0.99))\n",
        "\n",
        "    fixed_noise = torch.randn(5, z_dim).to(device)\n",
        "\n",
        "    max_steps = epochs*len(loader)\n",
        "    progress_bar = display(progress(0, 0, max_steps), display_id=True)\n",
        "    gen_losses = []\n",
        "    disc_losses = []\n",
        "    steps = 0\n",
        "    for epoch in range(epochs):\n",
        "        for i, real in enumerate(loader):\n",
        "          real = real.to(device)\n",
        "          batch_size = len(real)\n",
        "          \n",
        "          # random standard normal noise for generator\n",
        "          noise = torch.randn(batch_size, z_dim).to(device)\n",
        "\n",
        "          ### Train Discriminator ###\n",
        "          # Generator generates a fake image\n",
        "          fake = gen(noise)\n",
        "\n",
        "          # Pass the fake and real image to the discriminator\n",
        "          # Next don't forget to give a detached fake to the discriminator\n",
        "          # since we do not want to backdrop to generator yet \n",
        "          disc_fake_pred, disc_fake_pred_sigmoid, fm_fake = disc(fake.detach())\n",
        "          disc_real_pred, disc_real_pred_sigmoid, fm_real = disc(real)\n",
        "\n",
        "          # Calculate discriminator loss\n",
        "          noise = torch.rand_like(disc_real_pred) / 10\n",
        "          disc_loss_real = sigmoid_cross_entropy_with_logits(disc_real_pred, torch.ones_like(disc_real_pred)).mean()\n",
        "          noise = torch.rand_like(disc_real_pred) / 10\n",
        "          disc_loss_fake = sigmoid_cross_entropy_with_logits(disc_fake_pred, torch.zeros_like(disc_fake_pred)).mean()\n",
        "          disc_loss = (disc_loss_real + disc_loss_fake) / 2\n",
        "\n",
        "          disc_opt.zero_grad()\n",
        "          disc_loss.backward()\n",
        "          disc_opt.step()\n",
        "\n",
        "          ### Train Generator ###\n",
        "         # for i in range(2): # Potentially train generator multiple times per discriminator train time\n",
        "          # Get the discriminator's probability for the fake images\n",
        "          disc_fake_pred, disc_fake_pred_sigmoid, fm_fake = disc(fake)\n",
        "\n",
        "          # Calculate discriminator loss\n",
        "          gen_loss = sigmoid_cross_entropy_with_logits(disc_fake_pred, torch.ones_like(disc_fake_pred)).mean()\n",
        "\n",
        "          # Feature matching\n",
        "          mse_loss = nn.MSELoss(reduction='mean')\n",
        "          fm_g_loss1 = torch.mul(mse_loss(fake.mean(), real.mean()), 1)\n",
        "          fm_g_loss2 = torch.mul(mse_loss(fm_fake.mean(), fm_real.mean()), 1)\n",
        "          #print('gen loss: {}, fm_g_loss1: {}, fm_g_loss2: {}'.format(gen_loss, fm_g_loss1, fm_g_loss2))\n",
        "          total_gen_loss = gen_loss + fm_g_loss1 + fm_g_loss2\n",
        "\n",
        "          gen_opt.zero_grad()\n",
        "          gen_loss.backward()\n",
        "          gen_opt.step()\n",
        "\n",
        "          gen_losses.append(gen_loss.item())\n",
        "          disc_losses.append(disc_loss.item())\n",
        "\n",
        "          progress_bar.update(progress(steps, (gen_losses[-1], disc_losses[-1]), max_steps))\n",
        "          steps += 1\n",
        "\n",
        "        ### Visualize the fake images\n",
        "        if (epoch + 1) % 100 == 0:\n",
        "          fig = plt.figure(figsize = (10, 10))\n",
        "          ax = fig.add_subplot(111)\n",
        "          fake = gen(fixed_noise)\n",
        "          fake = fake.permute(0, 2, 1, 3).flatten(2, 3).flatten(0, 1).transpose(0,1)\n",
        "          #fake = fake.view(1, -1, 360).squeeze(0).transpose(0, 1)\n",
        "          fake = fake.detach().cpu().numpy()\n",
        "          ax.imshow(fake, cmap='gray_r', vmin=0, vmax=1, interpolation = 'nearest')\n",
        "          plt.title('Epoch {} Fake'.format(epoch))\n",
        "          plt.show()\n",
        "\n",
        "          fig = plt.figure(figsize = (10, 10))\n",
        "          ax = fig.add_subplot(111)\n",
        "          fake[fake < 0.7] = 0.0\n",
        "          ax.imshow(fake, cmap='gray_r', vmin=0, vmax=1, interpolation = 'nearest')\n",
        "          plt.title('Epoch {} Fake <0.8 set to 0'.format(epoch))\n",
        "          plt.show()\n",
        "\n",
        "          fig = plt.figure(figsize = (6, 6))\n",
        "          ax = fig.add_subplot(111)\n",
        "          real = real[0:5, :, :, :] # Subset only the first 20 samples, only piano part\n",
        "          real = real.permute(0, 2, 1, 3).flatten(2, 3).flatten(0, 1).transpose(0,1)\n",
        "          real = real.detach().cpu().numpy()\n",
        "          ax.imshow(real, cmap='gray_r', vmin=0, vmax=1, interpolation='nearest')\n",
        "          #ax.set_aspect(5)\n",
        "          plt.title('Epoch {} Real'.format(epoch))\n",
        "          plt.show()\n",
        "\n",
        "          print('Epoch {} at {}'.format(epoch, datetime.now()))\n",
        "        \n",
        "        # Save checkpoints\n",
        "        if (epoch + 1) % 500 == 0:\n",
        "          save_path = os.path.join(root_dir, 'GAN Checkpoints', 'gan_25apr_11_checkpoint_gen_{}'.format(epoch + start_epoch))\n",
        "          torch.save(gen.state_dict(), save_path)\n",
        "          save_path = os.path.join(root_dir, 'GAN Checkpoints', 'gan_25apr_11_checkpoint_disc_{}'.format(epoch + start_epoch))\n",
        "          torch.save(disc.state_dict(), save_path)\n",
        "\n",
        "          with open(os.path.join(root_dir, 'GAN Checkpoints', 'gan_25apr_11_gen_loss'), 'w') as outfile:\n",
        "            json.dump(gen_losses, outfile)\n",
        "          with open(os.path.join(root_dir, 'GAN Checkpoints', 'gan_25apr_11_disc_loss'), 'w') as outfile:\n",
        "            json.dump(disc_losses, outfile)\n",
        "\n",
        "\n",
        "    plt.plot(gen_losses, label='Generator loss')\n",
        "    plt.plot(disc_losses, label='Discriminator loss')\n",
        "    plt.xlabel('Batches')\n",
        "    plt.ylabel('Training loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BbmCnXXW-lr"
      },
      "outputs": [],
      "source": [
        "# Input size: [batch_size x 5 x 16 x 128]\n",
        "\n",
        "# **CHANGED FROM 128 TO 72\n",
        "\n",
        "class DiscConvNet(nn.Module):\n",
        "  def __init__(self, input_length = 16):\n",
        "    super(DiscConvNet, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels = 5, out_channels = 16, kernel_size = (2, 72), stride = (2,2))\n",
        "    self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = (2, 1), stride = (2,2))\n",
        "    self.conv3 = nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = (2, 1), stride = (2,2))\n",
        "    self.conv4 = nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = (2, 1), stride = (2,2))\n",
        "    self.conv5 = nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = (2, 1), stride = (2,2))\n",
        "    #self.fc1 = nn.Linear(64 * 2, 128)\n",
        "    #self.fc2 = nn.Linear(128, 128)\n",
        "    self.out = nn.Linear(16 * 2, 1)\n",
        "    self.prelu = nn.PReLU()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.batch_norm_2d = nn.BatchNorm2d(16)\n",
        "    self.batch_norm_1d = nn.BatchNorm1d(128)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "  def forward(self, input): # Input size: [batch_size x 5 x 16 x 128]\n",
        "    x = self.prelu(self.batch_norm_2d(self.conv1(input))) # [batch_size x 64 x 8 x 1]\n",
        "    fm = x.clone()\n",
        "    x = self.dropout(x)\n",
        "    x = self.prelu(self.batch_norm_2d(self.conv2(x))) # [batch_size x 64 x 4 x 1]\n",
        "    x = self.dropout(x)\n",
        "    x = self.prelu(self.batch_norm_2d(self.conv3(x))) # [batch_size x 64 x 2 x 1]\n",
        "    x = self.dropout(x)\n",
        "    x = self.prelu(self.batch_norm_2d(self.conv4(x))) # [batch_size x 64 x 2 x 1]\n",
        "    x = self.dropout(x)\n",
        "    x = self.prelu(self.batch_norm_2d(self.conv5(x))) # [batch_size x 64 x 2 x 1]\n",
        "    x = x.flatten(1, -1) # [batch_size x 128]\n",
        "    #x = self.prelu(self.batch_norm_1d(self.fc1(x))) # [batch_size x 128]\n",
        "    #x = self.prelu(self.batch_norm_1d(self.fc2(x))) # [batch_size x 128]\n",
        "    x = self.out(x)\n",
        "    x_sigmoid = self.sigmoid(x) # [batch_size x 1]\n",
        "    return x, x_sigmoid, fm\n",
        "\n",
        "\n",
        "class DiscMLP(nn.Module):\n",
        "  def __init__(self, input_length = 16):\n",
        "    super(DiscMLP, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(5 * 16 * 72, 256)\n",
        "    self.fc2 = nn.Linear(256, 128)\n",
        "    self.fc3 = nn.Linear(128, 128)\n",
        "    self.out = nn.Linear(128, 1)\n",
        "    self.prelu = nn.PReLU()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    self.bn256 = nn.BatchNorm1d(256)\n",
        "    self.bn128 = nn.BatchNorm1d(128)\n",
        "\n",
        "  def forward(self, input):\n",
        "\n",
        "    x = input.view(-1, 5 * 16 * 72)\n",
        "    x = self.prelu(self.bn256(self.fc1(x)))\n",
        "    x = self.dropout(x)\n",
        "    x = self.prelu(self.bn128(self.fc2(x)))\n",
        "    x = self.dropout(x)\n",
        "    x = self.prelu(self.bn128(self.fc3(x)))\n",
        "    x = self.out(x)\n",
        "    x_sigmoid = self.sigmoid(x)\n",
        "    fm = torch.zeros_like(input)\n",
        "\n",
        "    return x, x_sigmoid, fm\n",
        "\n",
        "class GenConvNet(nn.Module):\n",
        "  def __init__(self, z_dim = 100, input_length = 16):\n",
        "    super(GenConvNet, self).__init__()\n",
        "    self.z_dim = z_dim\n",
        "\n",
        "    #self.fc1 = nn.Linear(z_dim, 128)\n",
        "    #self.fc2 = nn.Linear(128, 128)\n",
        "    self.transpose_conv1 = nn.ConvTranspose2d(in_channels = z_dim, out_channels = 64, kernel_size = (2, 1), stride = (2,2))\n",
        "    self.transpose_conv2 = nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = (2, 1), stride = (2,2))\n",
        "    self.transpose_conv3 = nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = (2, 1), stride = (2,2))\n",
        "    self.transpose_conv4 = nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = (2, 1), stride = (2,2))\n",
        "    self.transpose_conv5 = nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = (2, 1), stride = (2,2))\n",
        "    self.transpose_conv6 = nn.ConvTranspose2d(in_channels = 64, out_channels = 5, kernel_size = (2, 72), stride = (2,2))\n",
        "    self.prelu = nn.PReLU()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.batch_norm_2d = nn.BatchNorm2d(64)\n",
        "    self.batch_norm_1d = nn.BatchNorm1d(128)\n",
        "\n",
        "  def forward(self, input):\n",
        "    #x = self.prelu(self.batch_norm_1d(self.fc1(input)))\n",
        "    #x = self.prelu(self.batch_norm_1d(self.fc2(x)))\n",
        "    x = input.view(-1, self.z_dim, 1, 1)\n",
        "    x = self.prelu(self.batch_norm_2d(self.transpose_conv1(x)))\n",
        "    x = self.prelu(self.batch_norm_2d(self.transpose_conv2(x)))\n",
        "    x = self.prelu(self.batch_norm_2d(self.transpose_conv3(x)))\n",
        "    x = self.prelu(self.batch_norm_2d(self.transpose_conv4(x)))\n",
        "    x = self.prelu(self.batch_norm_2d(self.transpose_conv5(x)))\n",
        "    x = self.sigmoid(self.transpose_conv6(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ltv1slZxl9N"
      },
      "outputs": [],
      "source": [
        "a = mini_data_concat_binary[:, 5000:5200, :].contiguous()\n",
        "a = a.view(1, -1, 72).squeeze(0).detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "WTieCVPjxozw",
        "outputId": "a993cc8e-39c2-4722-d215-301af9a545cf"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (10, 10))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(a, cmap = 'gray_r', interpolation = 'nearest')\n",
        "ax.set_aspect(0.2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2ro4rwZkHba"
      },
      "outputs": [],
      "source": [
        "mini_dataset = GANMusicDatasetDeterministic(mini_data_concat_binary, seq_length = 64)\n",
        "mini_loader = DataLoader(mini_dataset, batch_size = 64, \n",
        "                                     drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19GDRZMqa-RA"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1 and classname.find('ConvNet') == -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "plf5z_mfV4g9",
        "outputId": "d38af050-dca1-4f43-c376-146cffb97936"
      },
      "outputs": [],
      "source": [
        "z_dim = 100\n",
        "disc = DiscConvNet()\n",
        "gen = GenConvNet()\n",
        "disc.apply(weights_init)\n",
        "gen.apply(weights_init)\n",
        "#gen.load_state_dict(torch.load(os.path.join(root_dir, 'GAN Checkpoints', 'gan_25apr_10_checkpoint_gen_999')))\n",
        "#disc.load_state_dict(torch.load(os.path.join(root_dir, 'GAN Checkpoints', 'gan_25apr_10_checkpoint_disc_999')))\n",
        "train_full_GAN(gen, disc, mini_loader, z_dim, epochs = 1000, start_epoch = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5FhrtO_fAFw"
      },
      "outputs": [],
      "source": [
        "# Generate some music samples\n",
        "random_z = torch.randn((10,100)).to(device)\n",
        "generated_sample = gen(random_z)\n",
        "# Concatenate all the samples\n",
        "#generated_sample = generated_sample.view(5, -1, 128)\n",
        "generated_sample = generated_sample.permute(1, 0, 2, 3).flatten(1, 2)\n",
        "\n",
        "# Bring back to 128 pitches\n",
        "predictions = torch.zeros((5, 640, 128), dtype = torch.float32)\n",
        "predictions[:, :, 24:96] = generated_sample\n",
        "predictions[predictions < 0.7] = 0.0\n",
        "predictions = predictions * 127"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K7OgG8yfgq7"
      },
      "outputs": [],
      "source": [
        "# predictions = generated_sample.clone()\n",
        "# predictions[predictions < 0.5] = 0.0\n",
        "# predictions = predictions * 127"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "dmVa9s-UgCPS",
        "outputId": "0ed425e5-a6e8-4d90-b46f-988f6931baf9"
      },
      "outputs": [],
      "source": [
        "# Convert predictions into the multitrack pianoroll\n",
        "piano_track = pypianoroll.StandardTrack(name = 'Piano', program = 0, is_drum = False, pianoroll = predictions[0, :, :].detach().cpu().numpy())\n",
        "guitar_track = pypianoroll.StandardTrack(name = 'Guitar', program = 24, is_drum = False, pianoroll = predictions[1, :, :].detach().cpu().numpy())\n",
        "bass_track = pypianoroll.StandardTrack(name = 'Bass', program = 32, is_drum = False, pianoroll = predictions[2, :, :].detach().cpu().numpy())\n",
        "strings_track = pypianoroll.StandardTrack(name = 'Strings', program = 48, is_drum = False, pianoroll = predictions[3, :, :].detach().cpu().numpy())\n",
        "drums_track = pypianoroll.StandardTrack(name = 'Drums', is_drum = True, pianoroll = predictions[4, :, :].detach().cpu().numpy())\n",
        "\n",
        "generated_multitrack = pypianoroll.Multitrack(name = 'Generated', resolution = 4, tracks = [piano_track, guitar_track, bass_track, strings_track])\n",
        "\n",
        "#resolution=24, tempo=array(shape=(12000,), dtype=float64), downbeat=array(shape=(12000,), dtype=bool)\n",
        "# Plot the generated multitrack\n",
        "generated_multitrack.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "hxTlpBmCgP50",
        "outputId": "1b4e0601-fae7-4088-b392-ac32a97154c8"
      },
      "outputs": [],
      "source": [
        "# Convert generated multitrack to pretty midi\n",
        "generated_pm = pypianoroll.to_pretty_midi(generated_multitrack)\n",
        "generated_midi_audio = generated_pm.fluidsynth()\n",
        "IPython.display.Audio(generated_midi_audio, rate = 44100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "GAN Music Generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
